{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5dlsP07d4JV",
        "outputId": "d91aa45a-e173-449a-9018-c1933859dfdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#From https://www.kaggle.com/competitions/novozymes-enzyme-stability-prediction\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "cvE2Fha1d-gv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/train.csv\")"
      ],
      "metadata": {
        "id": "gcOf7bTReS9Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "e0FKzcz_0mAF",
        "outputId": "02e9853b-df67-40ae-fa58-fc6b1f65c34d"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   seq_id                                   protein_sequence   pH  \\\n",
              "0       0  AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...  7.0   \n",
              "1       1  AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...  7.0   \n",
              "2       2  AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...  7.0   \n",
              "3       3  AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...  7.0   \n",
              "4       4  AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...  7.0   \n",
              "\n",
              "                         data_source    tm  \\\n",
              "0  doi.org/10.1038/s41592-020-0801-4  75.7   \n",
              "1  doi.org/10.1038/s41592-020-0801-4  50.5   \n",
              "2  doi.org/10.1038/s41592-020-0801-4  40.5   \n",
              "3  doi.org/10.1038/s41592-020-0801-4  47.2   \n",
              "4  doi.org/10.1038/s41592-020-0801-4  49.5   \n",
              "\n",
              "                                                 seq  \\\n",
              "0  [0, 0, 0, 0, 2, 0, 0, 0, 3, 0, 2, 2, 4, 5, 0, ...   \n",
              "1  [0, 0, 0, 7, 3, 4, 5, 2, 15, 17, 4, 4, 4, 10, ...   \n",
              "2  [0, 0, 0, 12, 16, 14, 5, 10, 0, 14, 16, 18, 10...   \n",
              "3  [0, 0, 0, 16, 3, 2, 10, 14, 0, 8, 5, 0, 11, 5,...   \n",
              "4  [0, 0, 0, 14, 1, 16, 3, 5, 10, 10, 11, 16, 11,...   \n",
              "\n",
              "                                              counts  \n",
              "0  [0.13196480938416422, 0.0469208211143695, 0.10...  \n",
              "1  [0.0979020979020979, 0.06643356643356643, 0.08...  \n",
              "2  [0.1006036217303823, 0.07847082494969819, 0.03...  \n",
              "3  [0.07547169811320754, 0.06415094339622641, 0.1...  \n",
              "4  [0.059269469331495524, 0.04686423156443832, 0....  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01447fe4-e446-43d8-8455-531af6f07376\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>seq_id</th>\n",
              "      <th>protein_sequence</th>\n",
              "      <th>pH</th>\n",
              "      <th>data_source</th>\n",
              "      <th>tm</th>\n",
              "      <th>seq</th>\n",
              "      <th>counts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>AAAAKAAALALLGEAPEVVDIWLPAGWRQPFRVFRLERKGDGVLVG...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
              "      <td>75.7</td>\n",
              "      <td>[0, 0, 0, 0, 2, 0, 0, 0, 3, 0, 2, 2, 4, 5, 0, ...</td>\n",
              "      <td>[0.13196480938416422, 0.0469208211143695, 0.10...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>AAADGEPLHNEEERAGAGQVGRSLPQESEEQRTGSRPRRRRDLGSR...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
              "      <td>50.5</td>\n",
              "      <td>[0, 0, 0, 7, 3, 4, 5, 2, 15, 17, 4, 4, 4, 10, ...</td>\n",
              "      <td>[0.0979020979020979, 0.06643356643356643, 0.08...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>AAAFSTPRATSYRILSSAGSGSTRADAPQVRRLHTTRDLLAKDYYA...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
              "      <td>40.5</td>\n",
              "      <td>[0, 0, 0, 12, 16, 14, 5, 10, 0, 14, 16, 18, 10...</td>\n",
              "      <td>[0.1006036217303823, 0.07847082494969819, 0.03...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>AAASGLRTAIPAQPLRHLLQPAPRPCLRPFGLLSVRAGSARRSGLL...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
              "      <td>47.2</td>\n",
              "      <td>[0, 0, 0, 16, 3, 2, 10, 14, 0, 8, 5, 0, 11, 5,...</td>\n",
              "      <td>[0.07547169811320754, 0.06415094339622641, 0.1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>AAATKSGPRRQSQGASVRTFTPFYFLVEPVDTLSVRGSSVILNCSA...</td>\n",
              "      <td>7.0</td>\n",
              "      <td>doi.org/10.1038/s41592-020-0801-4</td>\n",
              "      <td>49.5</td>\n",
              "      <td>[0, 0, 0, 14, 1, 16, 3, 5, 10, 10, 11, 16, 11,...</td>\n",
              "      <td>[0.059269469331495524, 0.04686423156443832, 0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01447fe4-e446-43d8-8455-531af6f07376')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01447fe4-e446-43d8-8455-531af6f07376 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01447fe4-e446-43d8-8455-531af6f07376');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_seq = {'A': 0}\n",
        "\n",
        "max_seq = 0\n",
        "\n",
        "def get_char_index(c):\n",
        "    \n",
        "    if c in char_seq.keys():\n",
        "        return char_seq[c]\n",
        "    else:\n",
        "        char_seq[c] = len(char_seq)\n",
        "    \n",
        "    return len(char_seq)\n",
        "        \n",
        "    \n",
        "def to_seq(string):\n",
        "    \n",
        "    new_seq = [get_char_index(c) for c in string]\n",
        "    \n",
        "    return new_seq\n",
        "\n",
        "def get_counts(seq):\n",
        "    \n",
        "    counts = np.zeros(len(char_seq) + 1)\n",
        "    \n",
        "    for i, c in enumerate(char_seq.keys()):\n",
        "        counts[i] = sum([x == c for x in seq]) / len(seq)\n",
        "        \n",
        "    counts[len(char_seq)] = len(seq) / 1_000\n",
        "        \n",
        "    return counts\n",
        "\n",
        "def create_features(df):\n",
        "    \n",
        "    df['seq'] = df['protein_sequence'].apply(to_seq)\n",
        "    \n",
        "    df['counts'] = df['protein_sequence'].apply(get_counts)\n",
        "        \n",
        "    print(len(char_seq))\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "vp1_XQTMeYXp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = create_features(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_x53kyz5eaIE",
        "outputId": "c4f8eb54-6f78-4e9a-efe3-5b823a1b9673"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8G1EI_LQndQP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from keras.preprocessing import sequence\n",
        "max_words = 1_000\n",
        "\n",
        "X = tensorflow.keras.preprocessing.sequence.pad_sequences(df['seq'].values, maxlen=max_words)\n",
        "\n",
        "\n",
        "y = df['tm'].values"
      ],
      "metadata": {
        "id": "Q7AAM4JifJU9"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=X.reshape(X.shape[0],X.shape[1],1)"
      ],
      "metadata": {
        "id": "bLNhqwZT0UZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
      ],
      "metadata": {
        "id": "LpwOeNNcfM_K"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(tensorflow.keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, feat_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = tensorflow.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = tensorflow.keras.Sequential(\n",
        "            [tensorflow.keras.layers.Dense(ff_dim, activation=\"gelu\"), tensorflow.keras.layers.Dense(feat_dim),]\n",
        "        )\n",
        "        self.layernorm1 = tensorflow.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tensorflow.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = tensorflow.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tensorflow.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)"
      ],
      "metadata": {
        "id": "BIouV7ORaUum"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feat_dim = X_train.shape[-1] + 32\n",
        "embed_dim = 64  # Embedding size for attention\n",
        "num_heads = 8  # Number of attention heads\n",
        "ff_dim = 128  # Hidden layer size in feed forward network inside transformer\n",
        "dropout_rate = 0.0\n",
        "num_blocks = 12"
      ],
      "metadata": {
        "id": "yiP4xWLPa1ve"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    inputs = tensorflow.keras.layers.Input(shape=X_train.shape[-2:])\n",
        "        \n",
        "    # \"EMBEDDING LAYER\"\n",
        "    x = tensorflow.keras.layers.Dense(feat_dim)(inputs)\n",
        "    x = tensorflow.keras.layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    \n",
        "    # TRANSFORMER BLOCKS\n",
        "    for k in range(num_blocks):\n",
        "        x_old = x\n",
        "        transformer_block = TransformerBlock(embed_dim, feat_dim, num_heads, ff_dim, dropout_rate)\n",
        "        x = transformer_block(x)\n",
        "        x = 0.7*x + 0.3*x_old # SKIP CONNECTION\n",
        "    \n",
        "    # REGRESSION HEAD\n",
        "    x = tensorflow.keras.layers.Dense(128, activation=\"selu\")(x)\n",
        "    x = tensorflow.keras.layers.Dropout(dropout_rate)(x)\n",
        "    outputs = tensorflow.keras.layers.Dense(1, activation=\"linear\")(x)\n",
        "    model = tensorflow.keras.Model(inputs=inputs, outputs=outputs)\n",
        "        \n",
        "    return model"
      ],
      "metadata": {
        "id": "9z8ZpZJbnBrc"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=X_train.reshape(X_train.shape[0],X_train.shape[1],1)"
      ],
      "metadata": {
        "id": "fvKHkHJ1g6hU"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "LR_START = 1e-6\n",
        "LR_MAX = 6e-4\n",
        "LR_MIN = 1e-6\n",
        "LR_RAMPUP_EPOCHS = 0\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "EPOCHS = 420\n",
        "STEPS = [60,120,240]\n",
        "\n",
        "\n",
        "def lrfn(epoch):\n",
        "    if epoch<STEPS[0]:\n",
        "        epoch2 = epoch\n",
        "        EPOCHS2 = STEPS[0]\n",
        "    elif epoch<STEPS[0]+STEPS[1]:\n",
        "        epoch2 = epoch-STEPS[0]\n",
        "        EPOCHS2 = STEPS[1]\n",
        "    elif epoch<STEPS[0]+STEPS[1]+STEPS[2]:\n",
        "        epoch2 = epoch-STEPS[0]-STEPS[1]\n",
        "        EPOCHS2 = STEPS[2]\n",
        "    \n",
        "    if epoch2 < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch2 + LR_START\n",
        "    elif epoch2 < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        decay_total_epochs = EPOCHS2 - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n",
        "        decay_epoch_index = epoch2 - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n",
        "        phase = math.pi * decay_epoch_index / decay_total_epochs\n",
        "        cosine_decay = 0.5 * (1 + math.cos(phase))\n",
        "        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n",
        "    return lr\n",
        "\n",
        "rng = [i for i in range(EPOCHS)]\n",
        "lr_y = [lrfn(x) for x in rng]\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(rng, lr_y, '-o')\n",
        "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\". \\\n",
        "          format(lr_y[0], max(lr_y), lr_y[-1]))\n",
        "lr_callback = tensorflow.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)\n",
        "plt.xlabel('Epoch',size=14)\n",
        "plt.ylabel('Learning Rate',size=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7-lRttcGk5_9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "f6852ac1-e225-4cfb-8658-a43a6b45c860"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learning rate schedule: 0.0006 to 0.0006 to 1e-06\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n",
        "opt = tensorflow.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss=\"mse\", sample_weight_mode=\"temporal\",metrics=['RootMeanSquaredError'])"
      ],
      "metadata": {
        "id": "z4PkDAUgf67a"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "sN8BFT3og8vX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c9468d7-2df2-43d7-f4ea-958912809f56"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_15 (InputLayer)          [(None, 1000, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " dense_186 (Dense)              (None, 1000, 1032)   2064        ['input_15[0][0]']               \n",
            "                                                                                                  \n",
            " layer_normalization_169 (Layer  (None, 1000, 1032)  2064        ['dense_186[0][0]']              \n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " transformer_block_79 (Transfor  (None, 1000, 1032)  2385584     ['layer_normalization_169[0][0]']\n",
            " merBlock)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_144 (TFOpLamb  (None, 1000, 1032)  0           ['transformer_block_79[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_145 (TFOpLamb  (None, 1000, 1032)  0           ['layer_normalization_169[0][0]']\n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_72 (TFOpL  (None, 1000, 1032)  0           ['tf.math.multiply_144[0][0]',   \n",
            " ambda)                                                           'tf.math.multiply_145[0][0]']   \n",
            "                                                                                                  \n",
            " transformer_block_80 (Transfor  (None, 1000, 1032)  2385584     ['tf.__operators__.add_72[0][0]']\n",
            " merBlock)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_146 (TFOpLamb  (None, 1000, 1032)  0           ['transformer_block_80[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_147 (TFOpLamb  (None, 1000, 1032)  0           ['tf.__operators__.add_72[0][0]']\n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_73 (TFOpL  (None, 1000, 1032)  0           ['tf.math.multiply_146[0][0]',   \n",
            " ambda)                                                           'tf.math.multiply_147[0][0]']   \n",
            "                                                                                                  \n",
            " transformer_block_81 (Transfor  (None, 1000, 1032)  2385584     ['tf.__operators__.add_73[0][0]']\n",
            " merBlock)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_148 (TFOpLamb  (None, 1000, 1032)  0           ['transformer_block_81[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_149 (TFOpLamb  (None, 1000, 1032)  0           ['tf.__operators__.add_73[0][0]']\n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_74 (TFOpL  (None, 1000, 1032)  0           ['tf.math.multiply_148[0][0]',   \n",
            " ambda)                                                           'tf.math.multiply_149[0][0]']   \n",
            "                                                                                                  \n",
            " transformer_block_82 (Transfor  (None, 1000, 1032)  2385584     ['tf.__operators__.add_74[0][0]']\n",
            " merBlock)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_150 (TFOpLamb  (None, 1000, 1032)  0           ['transformer_block_82[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_151 (TFOpLamb  (None, 1000, 1032)  0           ['tf.__operators__.add_74[0][0]']\n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_75 (TFOpL  (None, 1000, 1032)  0           ['tf.math.multiply_150[0][0]',   \n",
            " ambda)                                                           'tf.math.multiply_151[0][0]']   \n",
            "                                                                                                  \n",
            " transformer_block_83 (Transfor  (None, 1000, 1032)  2385584     ['tf.__operators__.add_75[0][0]']\n",
            " merBlock)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_152 (TFOpLamb  (None, 1000, 1032)  0           ['transformer_block_83[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_153 (TFOpLamb  (None, 1000, 1032)  0           ['tf.__operators__.add_75[0][0]']\n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_76 (TFOpL  (None, 1000, 1032)  0           ['tf.math.multiply_152[0][0]',   \n",
            " ambda)                                                           'tf.math.multiply_153[0][0]']   \n",
            "                                                                                                  \n",
            " transformer_block_84 (Transfor  (None, 1000, 1032)  2385584     ['tf.__operators__.add_76[0][0]']\n",
            " merBlock)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_154 (TFOpLamb  (None, 1000, 1032)  0           ['transformer_block_84[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_155 (TFOpLamb  (None, 1000, 1032)  0           ['tf.__operators__.add_76[0][0]']\n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_77 (TFOpL  (None, 1000, 1032)  0           ['tf.math.multiply_154[0][0]',   \n",
            " ambda)                                                           'tf.math.multiply_155[0][0]']   \n",
            "                                                                                                  \n",
            " transformer_block_85 (Transfor  (None, 1000, 1032)  2385584     ['tf.__operators__.add_77[0][0]']\n",
            " merBlock)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_156 (TFOpLamb  (None, 1000, 1032)  0           ['transformer_block_85[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_157 (TFOpLamb  (None, 1000, 1032)  0           ['tf.__operators__.add_77[0][0]']\n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_78 (TFOpL  (None, 1000, 1032)  0           ['tf.math.multiply_156[0][0]',   \n",
            " ambda)                                                           'tf.math.multiply_157[0][0]']   \n",
            "                                                                                                  \n",
            " transformer_block_86 (Transfor  (None, 1000, 1032)  2385584     ['tf.__operators__.add_78[0][0]']\n",
            " merBlock)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_158 (TFOpLamb  (None, 1000, 1032)  0           ['transformer_block_86[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_159 (TFOpLamb  (None, 1000, 1032)  0           ['tf.__operators__.add_78[0][0]']\n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_79 (TFOpL  (None, 1000, 1032)  0           ['tf.math.multiply_158[0][0]',   \n",
            " ambda)                                                           'tf.math.multiply_159[0][0]']   \n",
            "                                                                                                  \n",
            " transformer_block_87 (Transfor  (None, 1000, 1032)  2385584     ['tf.__operators__.add_79[0][0]']\n",
            " merBlock)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_160 (TFOpLamb  (None, 1000, 1032)  0           ['transformer_block_87[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_161 (TFOpLamb  (None, 1000, 1032)  0           ['tf.__operators__.add_79[0][0]']\n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_80 (TFOpL  (None, 1000, 1032)  0           ['tf.math.multiply_160[0][0]',   \n",
            " ambda)                                                           'tf.math.multiply_161[0][0]']   \n",
            "                                                                                                  \n",
            " transformer_block_88 (Transfor  (None, 1000, 1032)  2385584     ['tf.__operators__.add_80[0][0]']\n",
            " merBlock)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_162 (TFOpLamb  (None, 1000, 1032)  0           ['transformer_block_88[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_163 (TFOpLamb  (None, 1000, 1032)  0           ['tf.__operators__.add_80[0][0]']\n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_81 (TFOpL  (None, 1000, 1032)  0           ['tf.math.multiply_162[0][0]',   \n",
            " ambda)                                                           'tf.math.multiply_163[0][0]']   \n",
            "                                                                                                  \n",
            " transformer_block_89 (Transfor  (None, 1000, 1032)  2385584     ['tf.__operators__.add_81[0][0]']\n",
            " merBlock)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_164 (TFOpLamb  (None, 1000, 1032)  0           ['transformer_block_89[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_165 (TFOpLamb  (None, 1000, 1032)  0           ['tf.__operators__.add_81[0][0]']\n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_82 (TFOpL  (None, 1000, 1032)  0           ['tf.math.multiply_164[0][0]',   \n",
            " ambda)                                                           'tf.math.multiply_165[0][0]']   \n",
            "                                                                                                  \n",
            " transformer_block_90 (Transfor  (None, 1000, 1032)  2385584     ['tf.__operators__.add_82[0][0]']\n",
            " merBlock)                                                                                        \n",
            "                                                                                                  \n",
            " tf.math.multiply_166 (TFOpLamb  (None, 1000, 1032)  0           ['transformer_block_90[0][0]']   \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_167 (TFOpLamb  (None, 1000, 1032)  0           ['tf.__operators__.add_82[0][0]']\n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_83 (TFOpL  (None, 1000, 1032)  0           ['tf.math.multiply_166[0][0]',   \n",
            " ambda)                                                           'tf.math.multiply_167[0][0]']   \n",
            "                                                                                                  \n",
            " dense_211 (Dense)              (None, 1000, 128)    132224      ['tf.__operators__.add_83[0][0]']\n",
            "                                                                                                  \n",
            " dropout_186 (Dropout)          (None, 1000, 128)    0           ['dense_211[0][0]']              \n",
            "                                                                                                  \n",
            " dense_212 (Dense)              (None, 1000, 1)      129         ['dropout_186[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28,763,489\n",
            "Trainable params: 28,763,489\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = EPOCHS\n",
        "BATCH_SIZE = 32\n",
        "NUM_FOLDS = 11\n",
        "VERBOSE = 1"
      ],
      "metadata": {
        "id": "59PYCvBumEfM"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, verbose=VERBOSE, epochs=EPOCH, batch_size=10)      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "i0nATUzre6Sw",
        "outputId": "09d9aa24-0282-44f3-e6e8-623acc1f9fc1"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/420\n",
            "2198/2198 [==============================] - 2884s 1s/step - loss: 204.3183 - root_mean_squared_error: 14.2923\n",
            "Epoch 2/420\n",
            " 402/2198 [====>.........................] - ETA: 39:06 - loss: 201.2674 - root_mean_squared_error: 14.1869"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-81-0fcf89df2309>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVERBOSE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1412\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1413\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1414\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1415\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    605\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 916\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1157\u001b[0m     \"\"\"\n\u001b[1;32m   1158\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1159\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}